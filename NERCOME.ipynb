{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NERCOME estimator to obtain covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "Nd = 4 # Number of random variables\n",
    "Ns = 6 # Number of data realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random matrix of size Nd x Ns\n",
    "A = np.random.normal(0, 1, size=(Nd//2, Ns))\n",
    "B = np.random.normal(0, np.sqrt(5), size=(Nd-Nd//2, Ns))\n",
    "X = np.vstack((A, B))\n",
    "# The resulting matrix X = (x_1, x_2, ..., x_Ns) consists of n column vectors,\n",
    "# of which each x_i has length p, the upper half has variance 1 and the lower half has variance 5\n",
    "\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard sample covariance estimator is given by\n",
    "$ \\hat{S} = \\frac{1}{N_s-1} X X^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 1/(Ns-1)*np.matmul(X, X.T)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the covariance matrix $ \\Sigma = \\mathbb{E}(\\hat{S}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_sum = np.zeros((Nd, Nd))\n",
    "n = 10\n",
    "for _ in range(n):\n",
    "    A = np.random.normal(0, 1, size=(Nd//2, Ns))\n",
    "    B = np.random.normal(0, np.sqrt(5), size=(Nd-Nd//2, Ns))\n",
    "    X = np.vstack((A, B))\n",
    "    S_sum += 1/(Ns-1)*np.matmul(X, X.T)\n",
    "CovM = S_sum / n\n",
    "print(CovM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NERCOME procedure divides the dataset into two subsamples, $X = (X_1, X_2)$, where $X_1$ is an $N_d \\times s$ matrix and $X_2$ is an $N_d \\times (N_s - s)$ matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(s, X):\n",
    "    Nd, Ns = X.shape\n",
    "    assert s >= 2 and s <= Ns and math.floor(s) == s\n",
    "    col_combos = list(it.combinations(range(Ns), s)) # Tuples of possible combinations of s out of Ns column indices\n",
    "\n",
    "    Z_sum = np.zeros((Nd, Nd))\n",
    "    S2_sum = np.zeros((Nd, Nd))\n",
    "\n",
    "    for col_combo in col_combos:\n",
    "        X1 = X[:, col_combo]\n",
    "        X2 = X[:, np.delete(range(Ns), col_combo)]\n",
    "        \n",
    "        S1 = 1/(s-1)*np.matmul(X1, X1.T)\n",
    "        S2 = 1/(Ns-s-1)*np.matmul(X2, X2.T)\n",
    "        S2_sum += S2\n",
    "        \n",
    "        # Diagonalize S_i = U_i * D_i * U_i^T\n",
    "        evals1, U1 = np.linalg.eigh(S1)\n",
    "        D1 = np.diag(evals1)\n",
    "        #evals2, U2 = np.linalg.eig(S2)\n",
    "        #D2 = np.diag(evals2)\n",
    "        \n",
    "        # Verify that the matrix diagonalization is correct (up to absolute error of 1e^-10)\n",
    "        S1_trial = np.matmul(np.matmul(U1, D1), U1.T)\n",
    "        #S2_trial = np.matmul(np.matmul(U2, D2), U2.T)\n",
    "        assert np.allclose(S1, S1_trial, 0, 1e-10)\n",
    "        #assert np.allclose(S2, S2_trial, 0, 1e-10)\n",
    "        \n",
    "        # Compute estimator Z = U_1 * diag(U_1^T * S_2 * U_1) * U_1^T\n",
    "        Z = np.matmul(np.matmul(U1, np.diag(np.diag(np.matmul(np.matmul(U1.T, S2), U1)))), U1.T)\n",
    "        Z_sum += Z\n",
    "    \n",
    "    Z_avg = Z_sum / len(col_combos)\n",
    "    S2_avg = S2_sum / len(col_combos)\n",
    "    M = Z_avg - S2_avg\n",
    "    \n",
    "    return np.trace(np.matmul(M, M.T)) # Frobenius matrix norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "Nd = 30 # Number of random variables\n",
    "Ns = 14 # Number of data realizations\n",
    "\n",
    "# Generate random matrix of size Nd x Ns\n",
    "A = np.random.normal(0, 1, size=(Nd//2, Ns))\n",
    "B = np.random.normal(0, np.sqrt(5), size=(Nd-Nd//2, Ns))\n",
    "X = np.vstack((A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 10 # Trial value for s\n",
    "print(Q(s, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
